<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag:Coursera | Cryo-Nyx Blog]]></title>
  <link href="http://blog.cryonyx.tk/tags/coursera/atom.xml" rel="self"/>
  <link href="http://blog.cryonyx.tk/"/>
  <updated>2013-08-07T23:19:56+08:00</updated>
  <id>http://blog.cryonyx.tk/</id>
  <author>
    <name><![CDATA[Cryonyx]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Algorithm Week 1~2 - Divide and Conquer]]></title>
    <link href="http://blog.cryonyx.tk/blog/2013/08/07/algo-004-divide-and-conquer/"/>
    <updated>2013-08-07T21:03:00+08:00</updated>
    <id>http://blog.cryonyx.tk/blog/2013/08/07/algo-004-divide-and-conquer</id>
    <content type="html"><![CDATA[<h2 id="divide-and-conquer-paradigm---">2 - Divide and Conquer Paradigm - 分治算法</h2>
<p>在解决某一特定问题的时候，递归是一种经常采用的思路，这一类算法不断地调用自身，以得出最后的结果。</p>

<p>但我发现身边的不少同学都对于递归算法存在一定程度上的误解，认为递归调用会导致时间和内存上的多余开销造成浪费，所以要尽量避免使用递归。在《C Primer Plus》里就提到了一个经典的递归算法——Fibonacci算法，当然了，是一个经典的糟糕算法。</p>

<p>因为fibonacci数列规定$Fib(n)=Fib(n-1)+Fib(n-2)$，所以自然就有了下面的算法：</p>

<p><code>c 糟糕的Fibonacci递归实现
int Fib(int n){
    if(n &gt; 2) return Fib(n-1) + Fib(n-2);
    return 1; //假设fibonacci前两项均为1
}
</code></p>

<p>从数学意义上来看完全没有问题，不过在计算机上这实在糟糕得不能再糟糕了。有兴趣的同学可以自己运行一下这段程序，记得不要把n定得太高了哦XD，在我的电脑上计算Fib(45)要花7秒的时间，计算Fib(46)用了9.5秒的时间（其实我还计算了一下Fib(50)，只用了76秒哦）。</p>

<p>虽然上面给出了一个糟糕的递归例子，但是通过对算法的学习，我们可以看到经过良好编写的递归程序具有强大的力量，而且形式优雅，给人一种化腐朽为神奇的感觉，那么下面进入正题。</p>

<p><code>Divide and Conquer</code>是一种使用递归来解决问题的办法，中文里边叫作<code>分治算法</code>，也就是<code>分而治之</code>。D&amp;C算法分为三步，一是Divide（分），二是Conquer（治），三是Combine（合）。先把大的复杂的问题分解成小的相对简单的问题，然后递归地解决这些相对容易的小问题，再把所有的结果综合起来得出原本问题的解。</p>

<p>在CLRS中对D&amp;C描述到：</p>

<blockquote>
  <p>1 - <strong>Divide</strong> the problem into a number of subproblems that are smaller instances of the same problem;</p>

  <p>2 - <strong>Conquer</strong> the subproblems by solving them recursively. If the problem sizes are small enough, however, just solve the subproblems in a straightforward manner;</p>

  <p>3 - <strong>Combine</strong> the solutions to the subproblems into the solution for the original problem.</p>
</blockquote>

<h3 id="merge-sort---">2.1 - Merge Sort - 归并排序</h3>
<p>这是一个排序算法，和我们熟悉的冒泡排序、插入排序、选择排序相比，这个算法面对大数据的时候占有很大优势，因为它的算法时间复杂度仅为$Θ(n\log_2n)$，而冒泡排序等都为$Θ(n^2)$。需要注意，$\log_2n$要远小于$n$哦，可以把$2^{20}$代进去看看。</p>

<h4 id="section">2.1.1 - 算法实现</h4>
<p>Merge Sort的思路完全符合D&amp;C：</p>

<p><strong>Divide：</strong>将$n$个元素的数组划分为两个$\frac{n}{2}$个元素的数组；</p>

<p><strong>Conquer：</strong>调用自身来递归地解决这两个比原数组小的排序问题。如果数组足够小（只有1个元素或1个元素也没有），那么就为<code>Base Case</code>，所以直接解决掉（在这里也就是什么都不做，不再继续调用自身）；</p>

<p><strong>Combine：</strong>这一点是整个归并排序中最重要的一点，把被分开的两个数组重新合并为一个数组，合并好的数组也就是排好序的原数组。</p>

<p>不再详解，这里给出C语言的实现代码。</p>

<p><code>c mergeSort.c
#include &lt;stdio.h&gt;
#define NUM 10
int L[NUM], R[NUM];
void merge(int A[], int p, int q, int r){    /* 合并两个数组 */
    int n1, n2, i, j, k;
    n1 = q+1-p;                 /* 左子数组的长度 */
    n2 = r-q;                   /* 右子数组的长度 */
    for(j = 0; j &lt; n1; ++j)
        L[j] = A[p+j];
    for(k = 0; k &lt; n2; ++k)
        R[k] = A[q+1+k];
    for(i = j = k = 0; j &lt; n1 &amp;&amp; k &lt; n2; i++){
        if(L[j] &gt; R[k]){
            A[p+i] = R[k];
            k++;
        }else{
            A[p+i] = L[j];
            j++;
        }
    }
    while(j &lt; n1){
        A[p+i] = L[j];
        i++;
        j++;
    }
    while(k &lt; n2){
        A[p+i] = R[k];
        i++;
        k++;
    }
}
void mergeSort(int A[], int p, int r){  /* Merge Sort主函数 */
    if(p &gt;= r) return;          /* Base Case */
    int q = (p+r)/2;            /* Divide */
    mergeSort(A, p, q);         /* Conquer */
    mergeSort(A, q+1, r);       /* Conquer */
    merge(A, p, q, r);          /* Combine */
}
int main(int argc, char *argv[]){
    int A[NUM], i;
    /* freopen("./input.txt", "r", stdin); */
    for(i = 0; i &lt; NUM; ++i)
        scanf("%d", &amp;A[i]);
    mergeSort(A, 0, NUM-1);
    for(i = 0; i &lt; NUM; ++i)
        printf("%d ", A[i]);
    printf("\n");
    return 0;
}
</code></p>

<p>对Merge Sort进行一些小小的修改，还可以用来计算逆序数（Inversions），因为是基于$Θ(n\log_2n)$的归并排序，所以计算逆序数的算法同样是$Θ(n\log_2n)$的时间复杂度。</p>

<h4 id="analysis-of-merge-sort---">2.1.2 - Analysis of Merge Sort - 分析归并算法</h4>

<p>上面已经提到，Merge Sort的算法时间复杂度是$Θ(n\log_2n)$，对于大数据来说优于插入排序等算法的$Θ(n^2)$。</p>

<p>但是为什么呢？为什么排序同样一个数组，把原数组分开成几个数组分别排序就比一起排序要快呢？分开排序不还多了一个Combine的步骤吗？</p>

<p>在继续讲算法分析之前，可以思考一下排序一个$n$个元素的数组，当然是在<code>Worst Case</code>的情况下（设$n$为$2$的幂）：</p>

<p><strong>1.</strong><code>插入排序</code>所需的<code>比较次数</code>为$\frac{n(n-1)}{2}=\frac{1}{2}n^2-\frac{1}{2}n$。</p>

<p><strong>2.</strong>下面我们还是使用<code>插入排序</code>，但是我们先把原数组分成两个$\frac{n}{2}$的数组来进行排序，然后将两个数组进行合并：显然对于每一个$\frac{n}{2}$个元素的数组来说，所需的<code>比较次数</code>为$\frac{\frac{n}{2}(\frac{n}{2}-1)}{2}=\frac{1}{8}n^2-\frac{1}{4}n$，因为有两个数组，再加上Combine所需进行的$n$次比较，一共所需的<code>比较次数</code>为$\frac{1}{4}n^2+\frac{1}{2}n$。</p>

<p>显然，通过对二次项系数的比较可知：只要$n$足够大，第二种方法是要优于第一种方法的。</p>

<p>你能看出来为什么吗？</p>

<p>其实这一次Divide减少了很多不必要的比较。方法1中，第i个数要和它前面的i-1个数比较，而Divide之后，前$\frac{n}{2}$个数比较次数不变，后$\frac{n}{2}$个数，每个数的比较次数却都减少了$\frac{n}{2}$，所以一共就减少了$\frac{1}{4}n^2$次比较，而这种方法是否实用，就看减少的比较次数$\frac{1}{4}n^2$和增加的比较次数$n$谁大谁小了。</p>

<p>这下子有点儿感觉了吧，要是继续Divide下去，减少的冗余比较岂不是更多？</p>

<p>下面来看看一个比较正式的分析：</p>

<p>在分析涉及递归的D&amp;C算法时，我们总可以把算法的运行时间表示为一个递推函数。</p>

<p>设Divide时把问题划分为a个子问题，每一个问题是原本问题大小的$\frac{1}{b}$，c是判断base case的常数，可得：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)=
\begin{cases}
Θ(1) &{n\leqslant c}\\
aT(\frac{n}{b})+D(n)+C(n) &{Otherwise}
\end{cases}
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>所以对于Merge Sort来说，$a=b=2$：</p>

<p><strong>Divide：</strong>对于归并排序来讲，这一步仅仅是一次计算而已，所以$D(n)=Θ(1)$。</p>

<p><strong>Conquer：</strong>每次递归解决两个大小为$\frac{n}{2}$的问题，可得运行时间为：$2T(\frac{n}{2})$。</p>

<p><strong>Combine：</strong>对于$n$个元素的数组来说，每次combine都需要花费$Θ(n)$的时间，所以$T(n)=Θ(n)$。</p>

<p>可得：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)=
\begin{cases}
Θ(1) &{n=1}\\
2T(\frac{n}{2})+Θ(n) &{n> 1}
\end{cases}
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>设c为解决$n=1$时和每个元素操作所需的常数时间，可将上式改写为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)=
\begin{cases}
c &{n=1}\\
2T(\frac{n}{2})+cn &{n> 1}
\end{cases}
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>对于Merge Sort的分析有两种方法，其一是利用<code>Recursion Tree</code>，可在CLRS 第34～37页找到详细内容。</p>

<hr />

<h3 id="quick-sort---">2.2 - Quick Sort - 快速排序</h3>
<p>快速排序是在实际情况中较常使用的一种排序算法，在C++的STL中就提供了qsort函数。不过我们还是来看看快速排序算法究竟是如何实现的。</p>

<p>快排算法和一般的插入排序、冒泡排序都不同，甚至和归并排序也大不同——虽然它们都是采用了<code>分治算法</code>的思路。在快速排序中涉及到了概率，也就是随机因素，所以快速排序算法一般用<code>平均算法时间复杂度</code>来衡量，而不是<code>Worst Case</code>。</p>

<p>在<code>Worst Case</code>下，快速排序算法的算法时间复杂度为$Θ(n^2)$，而在<code>Best Case</code>下为$Θ(n)$，平均复杂度为$Θ(nlog_2n)$。虽然它的平均运行时间才为$Θ(nlog_2n)$，而归并排序的<code>Worst Case</code>下运行时间就为$Θ(nlog_2n)$，但是快排在实际中一般仍然优于归并，这是因为算法时间复杂度并不能直接代表算法运行的快慢——只能表示运行时间增长的速度而已，毕竟常数项系数已经被隐去了。而快排在排序中是<code>In-Place</code>的，不需要额外建立数组并且复制回原数组，所以它的常数项系数要比归并小，总的来说仍然比归并快。</p>

<h4 id="section-1">2.2.1 - 算法实现</h4>
<p>快速排序算法的思路也很清晰，如下：</p>

<p><strong><em>Divide：</em></strong>选定<code>pivot</code>，将比<code>pivot</code>小的元素排列在<code>pivot</code>左边，比<code>pivot</code>大的元素排列在其右边。</p>

<p><strong><em>Conquer：</em></strong>对于不包含<code>pivot</code>的左右两个数组分别递归地调用自身解决问题。</p>

<p><strong><em>Combine：</em></strong>很幸运，这一步可以省略掉，因为此时原数组已经排好序了。</p>

<p>下面给出具体的C语言实现代码：</p>

<p><code>c Quick Sort.c
void swap(int *a, int *b){
    int t = *a;
    *a = *b;
    *b = t;
}
int partition(int A[], int left, int right){
    int i, j, pivot;
    pivot = A[left];          /* 选择数组第一个元素作为pivot */
    for(i = j = left+1; i &lt;= right; i++){  /* i指向当前元素，j指向大于pivot的第一个元素 */
        if(A[i] &lt; pivot){
            swap(&amp;A[i], &amp;A[j]);
            j++;
        }
    }
    swap(&amp;A[left], &amp;A[j-1]);
    count += right - left;
    return j-1;
}
void quickSort(int A[], int left, int right){
    if(left &gt;= right) return;
    int pivot = partition(A, left, right);
    quickSort(A, left, pivot - 1);
    quickSort(A, pivot + 1, right);
}
</code></p>

<h4 id="section-2">2.2.2 算法分析</h4>
<p>由上面的算法可知，每一次partition时，都将选定的pivot排到了正确的位置，并进一步缩小待排序的数组大小，减少可能的比较次数。</p>

<p>快速排序的运行时间取决于partition的步骤时分出的左右两个数组是否平衡。</p>

<h5 id="worst-case">2.2.2.1 Worst Case</h5>
<p><code>Worst Case</code>是快速排序算法Partition时最不平衡的一种情况，在这种情况下，每次partition都将现有n个元素的数组分为n-1和0的两个数组，于是这个算法的运行时间递推式就和线性搜索的递归实现的分析类似了，不同的是快速排序算法每一次partition是线性复杂度。所以可以得到：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)&=T(n-1)+T(0)+Θ(n)\\
&=T(n-1)+Θ(n)\\
&=Θ(n^2)
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>这个时候数组的元素为已经排好序的状态，不过进一步可以验证得到，无论输入数组是正向排好序还是逆向排好序，快速排序的运行时间均为$Θ(n^2)$，这一点和插入排序等算法存在差异，后者此时对于按要求排好序的数组的运行时间反而仅为$Θ(n)$。所以，当需要排序的元素已经一定程度上排好序的时候，选择快排还需谨慎啊。</p>

<h5 id="best-case">2.2.2.2 Best Case</h5>
<p>最为理想的平衡情况就是每次pivot都选取到中间大小的元素，所以每一次partition都将数组分为两个近似$\frac{n}{2}$大小的子数组（要排除pivot这个元素）。我们忽略一些细节，可以得到：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)&=2T(\frac{n}{2})+Θ(n)\\
&=Θ(nlog_2n)
\end{aligned}
\end{equation}
 %]]&gt;</script>

<h4 id="balenced-partitioning">2.2.2.3 Balenced Partitioning</h4>
<p>如果不按照$1:1$的比例划分数组而是按照其它的比例划分，那么partition还是平衡的吗？</p>

<p>下面假设每次partition将数组划分为$\frac{1}{10}$和$\frac{9}{10}$的两个部分，我们可以得到递推式：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)&=T(\frac{9n}{10})+T(\frac{n}{10})+cn
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>粗看上去是一个极不平衡的划分，不过我们可以来仔细的看一下，用<code>Recursion Tree</code>进行分析。因为每次将数组划分为9:1的比例，所以划分为$\frac{1}{10}$的数组肯定比另一部分要先到达叶子部分，此时每一层的消耗均为cn，从这一层开始，因为不再是满二叉树了，每一层节点数减少，所以每一层的消耗已经小于cn，综合起来每一层消耗即$O(n)$。</p>

<p>所以Recursion Tree的<code>Minimum Depth</code>为$log_{10}n=Θ(log_2n)$。</p>

<p>而<code>Maximum Depth</code>则为$log_{\frac{10}{9}}n=Θ(log_2n)$。</p>

<p>综上可得，$T(n)=O(nlog_2n)$，可见这仍旧是一个平衡的划分。</p>

<p>我们将其一般化，假设常数$0&lt;α\leqslant\frac{1}{2}$作为左子数组的划分大小，那么右子数组则划分为$1-α$，可得：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
T(n)&=T(αn)+T((1-α)n)+cn
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p><code>Minimum Depth</code>为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
log_{\frac{1}{α}}n&=\frac{log_2n}{log_2{\frac{1}{α}}}\\
&=Θ(log_2n)
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p><code>Maximum Depth</code>则为：</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{aligned}
log_{\frac{1}{1-α}}n&=\frac{log_2n}{log_2{\frac{1}{1-α}}}\\
&=Θ(log_2n)
\end{aligned}
\end{equation}
 %]]&gt;</script>

<p>可知每层的消耗还是不变，仍旧为$O(n)$，所以这几个量没有任何变化，$T(n)$仍旧为$O(nlog_2n)$。</p>

<p>所以，无关划分的大小，只要每一次partition时进行的划分是固定比例的，运行时间总是$O(nlog_2n)$，只是被Big-Oh隐藏住的常数项可能会大一点。</p>
]]></content>
  </entry>
  
</feed>
